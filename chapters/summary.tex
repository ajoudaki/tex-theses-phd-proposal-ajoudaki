Over the past two decades, there has been an exponential increase in the capacity of next-generation sequencing technologies~\cite{stephens2015big}. The magnitude of these sequence datasets has created a demand for statistics and machine learning algorithms that are capable of analyzing sequences, from hundreds of millions up to billions of nucleotides in length. Therefore, designing scalable algorithms and data-structures for bioinformatics application is the main focus of this research plan. 

Sketching and streaming algorithms are branches in algorithm design and provide a well-suited framework for designing scalable bioinformatics methods. Informally, streaming is a paradigm in which the algorithm takes one pass over the samples, and sketching refers to summarizing the relevant information during the pass. Crucially, memory complexity must remain sub-linear in the input size, since the input cannot fit into memory in its entirety. This assumption is necessary for many real-world datasets, such as multiple sequences alignment. The sketching-based algorithms are easy to implement and provide certain guarantees. These guarantees are often proved under realistic assumptions about data that can be independently verified. While sketching and streaming ideas have been successfully employed in information retrieval and compressive sensing, they have not been fully embraced by the bioinformatics community. Therefore, we set out to design algorithms and data-structures within the sketching and streaming framework, tackling computationally expensive problems such as inexact read to reference alignment, whole-genome alignment, multiple-genome alignment, synteny alignment, and visualization of genomes.